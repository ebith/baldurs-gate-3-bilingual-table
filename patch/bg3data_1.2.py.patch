--- orig/bg3data_1.2.py	2023-12-19 16:06:52.000000000 +0900
+++ bg3data_1.2.py	2024-05-19 05:53:47.318641800 +0900
@@ -1,3 +0,0 @@
-from lxml import etree
-import pandas as pd
-from pathlib import Path
@@ -5 +1,0 @@
-from datetime import datetime
@@ -6,0 +3,4 @@
+from datetime import datetime
+from pathlib import Path
+from typing import Any, Dict, List, Tuple, Union
+
@@ -8 +8 @@
-from typing import Dict, List, Any, Union, Tuple
+import pandas as pd
@@ -10 +9,0 @@
-
@@ -12,0 +12 @@
+from lxml import etree
@@ -33,2 +33,2 @@
-UNPACKED_DATA_FOLDER = Path('G:/BG3/Tools/bg3-modders-multitool/UnpackedData')
-OUTPUT_FOLDER = Path('G:/Dev/BG3/!Output/bg3data')
+UNPACKED_DATA_FOLDER = Path.cwd() / Path('bg3-modders-multitool/UnpackedData')
+OUTPUT_FOLDER = Path.cwd() / Path('!Output')
@@ -40 +40,7 @@
-    "Patch5_Hotfix2",
+    "Patch6_Hotfix2",
+    "Patch6_Hotfix3",
+    "Patch6_Hotfix4",
+    "Patch6_Hotfix6",
+    "Patch6_Hotfix7",
+    "Patch6_Hotfix8",
+    "Patch6_Hotfix9",
@@ -129 +135 @@
-        UNPACKED_DATA_FOLDER / folder_l1 / folder_l2 
+        UNPACKED_DATA_FOLDER / folder_l1 / folder_l2
@@ -136 +142 @@
-    for one_folder in all_folders:    
+    for one_folder in all_folders:
@@ -146 +152 @@
-        # for "template" records  -> "ParentTemplateId" 
+        # for "template" records  -> "ParentTemplateId"
@@ -154 +160 @@
-                    
+
@@ -161 +167 @@
-                    
+
@@ -175 +181 @@
-        UNPACKED_DATA_FOLDER / folder_l1 / folder_l2 
+        UNPACKED_DATA_FOLDER / folder_l1 / folder_l2
@@ -214 +220 @@
-    
+
@@ -222 +228 @@
-    
+
@@ -250 +256 @@
-     
+
@@ -255 +261 @@
-        
+
@@ -281 +287 @@
-            #### save all per type 
+            #### save all per type
@@ -305 +311 @@
-    
+
@@ -316 +322 @@
-        
+
@@ -346 +352 @@
-        
+
@@ -426 +432 @@
-        
+
@@ -428 +434 @@
-            UNPACKED_DATA_FOLDER / folder_l1 / folder_l2 
+            UNPACKED_DATA_FOLDER / folder_l1 / folder_l2
@@ -477 +483 @@
-            # bg3lib.save_to_excel_with_xlsxwriter_helper(data_dict, output_folder / "Excel Files" / f"Stats_{output_sheet}.xlsx", 
+            # bg3lib.save_to_excel_with_xlsxwriter_helper(data_dict, output_folder / "Excel Files" / f"Stats_{output_sheet}.xlsx",
@@ -479 +485 @@
-            # multiple sheets per book: 
+            # multiple sheets per book:
@@ -566,0 +573,114 @@
+@Timer(logger=logging.info, initial_text=True)
+def process_localization_folders(output_folder: Path) -> Dict_of_Dict:
+
+    logging.info("LOCALIZATION Folders - Start processing")
+
+    data_dict : Dict_of_Dict = {}
+
+    all_folders = [
+        UNPACKED_DATA_FOLDER / folder_l1 / folder_l2
+        for folder_l1 in ROOT_FOLDERS_L1
+        for folder_l2 in ROOT_FOLDERS_L2
+    ]
+
+    # List to hold all directories ending with 'Tags'
+    tag_folders = [d for folder in all_folders for d in folder.rglob('*/') if d.is_dir() and d.name == "Localization"]
+    for tag_folder in tag_folders:
+        logging.debug(f"LOCALIZATION - Processing '{tag_folder.relative_to(UNPACKED_DATA_FOLDER)}'")
+        bg3lib.process_lsx_files(UNPACKED_DATA_FOLDER, tag_folder, "TranslatedStringKey", "Content", data_dict)
+        #, post_process_tags_and_flags)
+    # --- Moving important columns in front of the records
+    columns_order = ["UUID", "Content"]
+
+    for column in ["Content"]:
+        for language in TRANSLATION_LANGUAGES:
+            columns_order.append(f"{column}{language}")
+
+    data_dict =  bg3lib.sort_data_dict_columns(data_dict, columns_order)
+
+    if Option_save_to_json_dict:
+        bg3lib.save_to_json_dict(data_dict, output_folder / "Json files (dict)" / "Localization_dict.json")
+    if Option_save_to_json_array:
+        bg3lib.save_to_json_array(data_dict, output_folder / "Json files (array)" / "Localization_array.json")
+    if Option_save_to_excel:
+        bg3lib.save_to_excel_with_xlsxwriter_helper(data_dict, output_folder / "Excel Files" / "Localization.xlsx", "Localization", columns_order)
+    if Option_save_to_sqlite:
+        bg3lib.save_data_dict_to_sqlite(data_dict, output_folder / "SQLite files" / "bg3data-localization.sqlite3", "Localization", columns_order)
+    return data_dict
+
+@Timer(logger=logging.info, initial_text=True)
+def process_journal_folders(output_folder: Path) -> Dict_of_Dict:
+
+    logging.info("JOURNAL Folders - Start processing")
+
+    data_dict : Dict_of_Dict = {}
+
+    all_folders = [
+        UNPACKED_DATA_FOLDER / folder_l1 / folder_l2
+        for folder_l1 in ROOT_FOLDERS_L1
+        for folder_l2 in ROOT_FOLDERS_L2
+    ]
+
+    # List to hold all directories ending with 'Tags'
+    tag_folders = [d for folder in all_folders for d in folder.rglob('*/') if d.is_dir() and d.name == "Journal"]
+    for tag_folder in tag_folders:
+        logging.debug(f"JOURNAL - Processing '{tag_folder.relative_to(UNPACKED_DATA_FOLDER)}'")
+        bg3lib.process_lsx_files(UNPACKED_DATA_FOLDER, tag_folder, "Quest", "QuestGuid", data_dict)
+        #, post_process_tags_and_flags)
+    # --- Moving important columns in front of the records
+    columns_order = ["QuestGuid", "QuestTitle"]
+
+    for column in ["QuestTitle"]:
+        for language in TRANSLATION_LANGUAGES:
+            columns_order.append(f"{column}{language}")
+
+    data_dict =  bg3lib.sort_data_dict_columns(data_dict, columns_order)
+
+    if Option_save_to_json_dict:
+        bg3lib.save_to_json_dict(data_dict, output_folder / "Json files (dict)" / "Journal_dict.json")
+    if Option_save_to_json_array:
+        bg3lib.save_to_json_array(data_dict, output_folder / "Json files (array)" / "Journal_array.json")
+    if Option_save_to_excel:
+        bg3lib.save_to_excel_with_xlsxwriter_helper(data_dict, output_folder / "Excel Files" / "Journal.xlsx", "Journal", columns_order)
+    if Option_save_to_sqlite:
+        bg3lib.save_data_dict_to_sqlite(data_dict, output_folder / "SQLite files" / "bg3data-journal.sqlite3", "Journal", columns_order)
+    return data_dict
+
+@Timer(logger=logging.info, initial_text=True)
+def process_feats_folders(output_folder: Path) -> Dict_of_Dict:
+
+    logging.info("FEATS Folders - Start processing")
+
+    data_dict : Dict_of_Dict = {}
+
+    all_folders = [
+        UNPACKED_DATA_FOLDER / folder_l1 / folder_l2
+        for folder_l1 in ROOT_FOLDERS_L1
+        for folder_l2 in ROOT_FOLDERS_L2
+    ]
+
+    # List to hold all directories ending with 'Tags'
+    tag_folders = [d for folder in all_folders for d in folder.rglob('*/') if d.is_dir() and d.name == "Feats"]
+    for tag_folder in tag_folders:
+        logging.debug(f"Feats - Processing '{tag_folder.relative_to(UNPACKED_DATA_FOLDER)}'")
+        bg3lib.process_lsx_files(UNPACKED_DATA_FOLDER, tag_folder, "FeatDescription", "UUID", data_dict)
+        #, post_process_tags_and_flags)
+    # --- Moving important columns in front of the records
+    columns_order = ["UUID", "DisplayName", "Description"]
+
+    for column in ["DisplayName", "Dicription"]:
+        for language in TRANSLATION_LANGUAGES:
+            columns_order.append(f"{column}{language}")
+
+    data_dict =  bg3lib.sort_data_dict_columns(data_dict, columns_order)
+
+    if Option_save_to_json_dict:
+        bg3lib.save_to_json_dict(data_dict, output_folder / "Json files (dict)" / "Feats_dict.json")
+    if Option_save_to_json_array:
+        bg3lib.save_to_json_array(data_dict, output_folder / "Json files (array)" / "Feats_array.json")
+    if Option_save_to_excel:
+        bg3lib.save_to_excel_with_xlsxwriter_helper(data_dict, output_folder / "Excel Files" / "Feats.xlsx", "Feats", columns_order)
+    if Option_save_to_sqlite:
+        bg3lib.save_data_dict_to_sqlite(data_dict, output_folder / "SQLite files" / "bg3data-feats.sqlite3", "Feats", columns_order)
+    return data_dict
+
@@ -579 +699 @@
-     
+
@@ -609 +729 @@
-    
+
@@ -612 +732 @@
-    
+
@@ -618 +738 @@
-    
+
@@ -624 +744 @@
-    
+
@@ -633,0 +754,6 @@
+    process_localization_folders(output_folder_stamped)
+
+    process_journal_folders(output_folder_stamped)
+
+    process_feats_folders(output_folder_stamped)
+
@@ -638,2 +764,3 @@
-    import cProfile, pstats  # noqa: E401
-    
+    import cProfile  # noqa: E401
+    import pstats
+
@@ -642 +769 @@
-    
+
@@ -650 +777 @@
-    
+
